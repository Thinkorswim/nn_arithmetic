{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.core import Dense, Dropout\n",
    "from keras.layers import Input, BatchNormalization, Activation\n",
    "from keras import regularizers\n",
    "from keras import initializers\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "\n",
    "from IPython import embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_data(dataset=\"data\"):\n",
    "    X = []\n",
    "    Y = []\n",
    "\n",
    "    f=open(dataset, 'r')\n",
    "    for line in f.readlines():\n",
    "        intLine = [int(s) for s in line.split(' ')]\n",
    "        X.append(intLine[:-1])\n",
    "        Y.append(intLine[-1:])\n",
    "\n",
    "    return np.array(X),np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_dense_model(input_size):\n",
    "    model = Sequential()\n",
    "    layer_size = 0\n",
    "\n",
    "    if input_size % 2 == 0:\n",
    "        layer_size = int(input_size/2 + 1)\n",
    "    else:\n",
    "        layer_size = int((input_size+1)/2)\n",
    "# #     layer_size = input_size*2\n",
    "\n",
    "    model.add(Dense(layer_size, kernel_initializer=\"orthogonal\", bias_initializer=initializers.zeros(), input_shape=(input_size,)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('selu'))\n",
    "    model.add(Dense(1,activation=\"sigmoid\"))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['binary_crossentropy', 'accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training examples: 1000\n",
      "Test examples: 0\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_43 (Dense)             (None, 2)                 6         \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 2)                 8         \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 17\n",
      "Trainable params: 13\n",
      "Non-trainable params: 4\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.6937 - binary_crossentropy: 0.6937 - acc: 0.4940\n",
      "Epoch 2/100\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.6936 - binary_crossentropy: 0.6936 - acc: 0.5120\n",
      "Epoch 3/100\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6935 - binary_crossentropy: 0.6935 - acc: 0.4980\n",
      "Epoch 4/100\n",
      " 563/1000 [===============>..............] - ETA: 2s - loss: 0.6938 - binary_crossentropy: 0.6938 - acc: 0.4991"
     ]
    }
   ],
   "source": [
    "    test_size = 0.0\n",
    "    epochs = 100\n",
    "    b_size = 10\n",
    "\n",
    "    avg_val = np.array([])\n",
    "    avg_train = np.array([])\n",
    "\n",
    "    X, Y = import_data()\n",
    "\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size, random_state=0)\n",
    "\n",
    "\n",
    "    print(\"\\nTraining examples: \" +  str(X_train.shape[0]))\n",
    "    print(\"Test examples: \" +  str(X_test.shape[0]))\n",
    "\n",
    "\n",
    "    classifier = create_dense_model(len(X_train[0]))\n",
    "    classifier.summary()\n",
    "\n",
    "    history = classifier.fit(X_train, Y_train, epochs=epochs, batch_size=b_size, verbose=1)\n",
    "    result = classifier.evaluate(X_test, Y_test, batch_size=b_size)\n",
    "\n",
    "#     avg_val = np.append(avg_val, result[2])\n",
    "    avg_train = np.append(avg_train, history.history['acc'][-1])\n",
    "\n",
    "\n",
    "\n",
    "#     print(\"\\nValidation Avg: \" + str(np.average(avg_val)))\n",
    "    print(\"Train Avg: \" + str(np.average(avg_train)))\n",
    "\n",
    "    print(\"\\n\")\n",
    "#     print(avg_val)\n",
    "    print(avg_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
