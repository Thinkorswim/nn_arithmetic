{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.layers import Input, LSTM, Flatten\n",
    "from keras import regularizers\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "\n",
    "from IPython import embed\n",
    "\n",
    "\n",
    "def import_data(dataset=\"data\"):\n",
    "    X = []\n",
    "    Y = []\n",
    "\n",
    "    f=open(dataset, 'r')\n",
    "    for line in f.readlines():\n",
    "        intLine = [int(s) for s in line.split(' ')]\n",
    "        X.append(intLine[:-1])\n",
    "        Y.append(intLine[-1:])\n",
    "\n",
    "    X = np.array(X)\n",
    "    X = X.reshape(X.shape[0], 1, X.shape[1])\n",
    "    Y = np.array(Y)\n",
    "    Y = Y.reshape(Y.shape[0], 1)\n",
    "\n",
    "    return X,Y\n",
    "\n",
    "def create_RNN_model(input_shape, neurons):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(neurons, input_shape=(input_shape[1], input_shape[2]), activation=\"selu\", kernel_initializer=\"lecun_uniform\", return_sequences=False))\n",
    "    model.add(Dense(1, activation=\"sigmoid\"))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='RMSprop', metrics=['binary_crossentropy','accuracy'])\n",
    "\n",
    "\n",
    "    return model\n",
    "\n",
    "def draw_figure(data, label, fig=None, ax=None):\n",
    "    # Plot the change in the validation set vs change in the training set\n",
    "    if not fig:\n",
    "        fig = plt.figure(figsize=(6, 4))\n",
    "    if not ax:\n",
    "        ax = fig.add_subplot(111)\n",
    "    \n",
    "    \n",
    "    real_data = []\n",
    "    scale = int(len(data[0])/50)\n",
    "    \n",
    "    \n",
    "    \n",
    "    for i in range(0, 50):\n",
    "        real_data.append(data[0][i*scale])\n",
    "    \n",
    "    ax.plot(np.arange(1, len(data[0]) + 1, scale), real_data, label=label)\n",
    "    ax.legend(loc='best')\n",
    "    ax.set_xlabel('Epoch number')\n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training examples: 80000\n",
      "Test examples: 20000\n",
      "Epochs: 100  -------  Try: 0\n",
      "Train on 80000 samples, validate on 20000 samples\n",
      "Epoch 1/100\n",
      "80000/80000 [==============================] - 6s 74us/step - loss: 0.6947 - binary_crossentropy: 0.6947 - acc: 0.5013 - val_loss: 0.6935 - val_binary_crossentropy: 0.6935 - val_acc: 0.5027\n",
      "Epoch 2/100\n",
      "80000/80000 [==============================] - 3s 39us/step - loss: 0.6935 - binary_crossentropy: 0.6935 - acc: 0.5052 - val_loss: 0.6935 - val_binary_crossentropy: 0.6935 - val_acc: 0.5022\n",
      "Epoch 3/100\n",
      "80000/80000 [==============================] - 3s 37us/step - loss: 0.6932 - binary_crossentropy: 0.6932 - acc: 0.5071 - val_loss: 0.6935 - val_binary_crossentropy: 0.6935 - val_acc: 0.5014\n",
      "Epoch 4/100\n",
      "80000/80000 [==============================] - 3s 35us/step - loss: 0.6930 - binary_crossentropy: 0.6930 - acc: 0.5104 - val_loss: 0.6938 - val_binary_crossentropy: 0.6938 - val_acc: 0.5007\n",
      "Epoch 5/100\n",
      "80000/80000 [==============================] - 3s 38us/step - loss: 0.6927 - binary_crossentropy: 0.6927 - acc: 0.5137 - val_loss: 0.6944 - val_binary_crossentropy: 0.6944 - val_acc: 0.5004\n",
      "Epoch 6/100\n",
      "80000/80000 [==============================] - 3s 35us/step - loss: 0.6925 - binary_crossentropy: 0.6925 - acc: 0.5165 - val_loss: 0.6937 - val_binary_crossentropy: 0.6937 - val_acc: 0.5055\n",
      "Epoch 7/100\n",
      "80000/80000 [==============================] - 3s 35us/step - loss: 0.6921 - binary_crossentropy: 0.6921 - acc: 0.5172 - val_loss: 0.6946 - val_binary_crossentropy: 0.6946 - val_acc: 0.5000\n",
      "Epoch 8/100\n",
      "80000/80000 [==============================] - 3s 34us/step - loss: 0.6918 - binary_crossentropy: 0.6918 - acc: 0.5205 - val_loss: 0.6942 - val_binary_crossentropy: 0.6942 - val_acc: 0.5012\n",
      "Epoch 9/100\n",
      "80000/80000 [==============================] - 3s 35us/step - loss: 0.6913 - binary_crossentropy: 0.6913 - acc: 0.5235 - val_loss: 0.6944 - val_binary_crossentropy: 0.6944 - val_acc: 0.5026\n",
      "Epoch 10/100\n",
      "80000/80000 [==============================] - 3s 38us/step - loss: 0.6911 - binary_crossentropy: 0.6911 - acc: 0.5271 - val_loss: 0.6953 - val_binary_crossentropy: 0.6953 - val_acc: 0.4986\n",
      "Epoch 11/100\n",
      "80000/80000 [==============================] - 3s 42us/step - loss: 0.6908 - binary_crossentropy: 0.6908 - acc: 0.5270 - val_loss: 0.6952 - val_binary_crossentropy: 0.6952 - val_acc: 0.5024\n",
      "Epoch 12/100\n",
      "80000/80000 [==============================] - 3s 36us/step - loss: 0.6907 - binary_crossentropy: 0.6907 - acc: 0.5291 - val_loss: 0.6956 - val_binary_crossentropy: 0.6956 - val_acc: 0.5006\n",
      "Epoch 13/100\n",
      "80000/80000 [==============================] - 4s 44us/step - loss: 0.6904 - binary_crossentropy: 0.6904 - acc: 0.5321 - val_loss: 0.6954 - val_binary_crossentropy: 0.6954 - val_acc: 0.5059\n",
      "Epoch 14/100\n",
      "80000/80000 [==============================] - 3s 39us/step - loss: 0.6902 - binary_crossentropy: 0.6902 - acc: 0.5307 - val_loss: 0.6964 - val_binary_crossentropy: 0.6964 - val_acc: 0.5004\n",
      "Epoch 15/100\n",
      "80000/80000 [==============================] - 3s 39us/step - loss: 0.6899 - binary_crossentropy: 0.6899 - acc: 0.5328 - val_loss: 0.6961 - val_binary_crossentropy: 0.6961 - val_acc: 0.5012\n",
      "Epoch 16/100\n",
      "80000/80000 [==============================] - 3s 34us/step - loss: 0.6897 - binary_crossentropy: 0.6897 - acc: 0.5354 - val_loss: 0.6965 - val_binary_crossentropy: 0.6965 - val_acc: 0.5016\n",
      "Epoch 17/100\n",
      "80000/80000 [==============================] - 3s 32us/step - loss: 0.6895 - binary_crossentropy: 0.6895 - acc: 0.5336 - val_loss: 0.6964 - val_binary_crossentropy: 0.6964 - val_acc: 0.5029\n",
      "Epoch 18/100\n",
      "80000/80000 [==============================] - 2s 30us/step - loss: 0.6893 - binary_crossentropy: 0.6893 - acc: 0.5347 - val_loss: 0.6961 - val_binary_crossentropy: 0.6961 - val_acc: 0.5007\n",
      "Epoch 19/100\n",
      "80000/80000 [==============================] - 3s 37us/step - loss: 0.6890 - binary_crossentropy: 0.6890 - acc: 0.5357 - val_loss: 0.6957 - val_binary_crossentropy: 0.6957 - val_acc: 0.5063\n",
      "Epoch 20/100\n",
      "80000/80000 [==============================] - 3s 32us/step - loss: 0.6886 - binary_crossentropy: 0.6886 - acc: 0.5385 - val_loss: 0.6965 - val_binary_crossentropy: 0.6965 - val_acc: 0.5002\n",
      "Epoch 21/100\n",
      "80000/80000 [==============================] - 2s 30us/step - loss: 0.6886 - binary_crossentropy: 0.6886 - acc: 0.5394 - val_loss: 0.6970 - val_binary_crossentropy: 0.6970 - val_acc: 0.5044\n",
      "Epoch 22/100\n",
      "80000/80000 [==============================] - 2s 30us/step - loss: 0.6882 - binary_crossentropy: 0.6882 - acc: 0.5387 - val_loss: 0.6980 - val_binary_crossentropy: 0.6980 - val_acc: 0.5038\n",
      "Epoch 23/100\n",
      "80000/80000 [==============================] - 2s 29us/step - loss: 0.6880 - binary_crossentropy: 0.6880 - acc: 0.5430 - val_loss: 0.6966 - val_binary_crossentropy: 0.6966 - val_acc: 0.5021\n",
      "Epoch 24/100\n",
      "80000/80000 [==============================] - 2s 29us/step - loss: 0.6877 - binary_crossentropy: 0.6877 - acc: 0.5430 - val_loss: 0.6979 - val_binary_crossentropy: 0.6979 - val_acc: 0.5030\n",
      "Epoch 25/100\n",
      "80000/80000 [==============================] - 2s 31us/step - loss: 0.6874 - binary_crossentropy: 0.6874 - acc: 0.5427 - val_loss: 0.6976 - val_binary_crossentropy: 0.6976 - val_acc: 0.5058\n",
      "Epoch 26/100\n",
      "80000/80000 [==============================] - 2s 31us/step - loss: 0.6873 - binary_crossentropy: 0.6873 - acc: 0.5432 - val_loss: 0.6982 - val_binary_crossentropy: 0.6982 - val_acc: 0.5018\n",
      "Epoch 27/100\n",
      "80000/80000 [==============================] - 2s 30us/step - loss: 0.6871 - binary_crossentropy: 0.6871 - acc: 0.5453 - val_loss: 0.6985 - val_binary_crossentropy: 0.6985 - val_acc: 0.5026\n",
      "Epoch 28/100\n",
      "80000/80000 [==============================] - 2s 28us/step - loss: 0.6866 - binary_crossentropy: 0.6866 - acc: 0.5459 - val_loss: 0.6988 - val_binary_crossentropy: 0.6988 - val_acc: 0.5037\n",
      "Epoch 29/100\n",
      "80000/80000 [==============================] - 2s 28us/step - loss: 0.6864 - binary_crossentropy: 0.6864 - acc: 0.5454 - val_loss: 0.6993 - val_binary_crossentropy: 0.6993 - val_acc: 0.5019\n",
      "Epoch 30/100\n",
      "80000/80000 [==============================] - 2s 29us/step - loss: 0.6861 - binary_crossentropy: 0.6861 - acc: 0.5463 - val_loss: 0.7011 - val_binary_crossentropy: 0.7011 - val_acc: 0.5010\n",
      "Epoch 31/100\n",
      "80000/80000 [==============================] - 2s 29us/step - loss: 0.6859 - binary_crossentropy: 0.6859 - acc: 0.5476 - val_loss: 0.7004 - val_binary_crossentropy: 0.7004 - val_acc: 0.5038\n",
      "Epoch 32/100\n",
      "80000/80000 [==============================] - 2s 29us/step - loss: 0.6856 - binary_crossentropy: 0.6856 - acc: 0.5501 - val_loss: 0.7004 - val_binary_crossentropy: 0.7004 - val_acc: 0.5044\n",
      "Epoch 33/100\n",
      "80000/80000 [==============================] - 2s 29us/step - loss: 0.6851 - binary_crossentropy: 0.6851 - acc: 0.5498 - val_loss: 0.7005 - val_binary_crossentropy: 0.7005 - val_acc: 0.5034\n",
      "Epoch 34/100\n",
      "80000/80000 [==============================] - 2s 28us/step - loss: 0.6850 - binary_crossentropy: 0.6850 - acc: 0.5509 - val_loss: 0.7009 - val_binary_crossentropy: 0.7009 - val_acc: 0.5048\n",
      "Epoch 35/100\n",
      "80000/80000 [==============================] - 2s 30us/step - loss: 0.6847 - binary_crossentropy: 0.6847 - acc: 0.5519 - val_loss: 0.7015 - val_binary_crossentropy: 0.7015 - val_acc: 0.5028\n",
      "Epoch 36/100\n",
      "80000/80000 [==============================] - 3s 39us/step - loss: 0.6845 - binary_crossentropy: 0.6845 - acc: 0.5522 - val_loss: 0.7005 - val_binary_crossentropy: 0.7005 - val_acc: 0.5051\n",
      "Epoch 37/100\n",
      "80000/80000 [==============================] - 3s 34us/step - loss: 0.6839 - binary_crossentropy: 0.6839 - acc: 0.5536 - val_loss: 0.7013 - val_binary_crossentropy: 0.7013 - val_acc: 0.5072\n",
      "Epoch 38/100\n",
      "80000/80000 [==============================] - 3s 40us/step - loss: 0.6837 - binary_crossentropy: 0.6837 - acc: 0.5541 - val_loss: 0.7028 - val_binary_crossentropy: 0.7028 - val_acc: 0.5006\n",
      "Epoch 39/100\n",
      "80000/80000 [==============================] - 4s 55us/step - loss: 0.6836 - binary_crossentropy: 0.6836 - acc: 0.5537 - val_loss: 0.7026 - val_binary_crossentropy: 0.7026 - val_acc: 0.5008\n",
      "Epoch 40/100\n",
      "80000/80000 [==============================] - 3s 37us/step - loss: 0.6832 - binary_crossentropy: 0.6832 - acc: 0.5561 - val_loss: 0.7022 - val_binary_crossentropy: 0.7022 - val_acc: 0.5018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/100\n",
      "80000/80000 [==============================] - 3s 36us/step - loss: 0.6829 - binary_crossentropy: 0.6829 - acc: 0.5564 - val_loss: 0.7032 - val_binary_crossentropy: 0.7032 - val_acc: 0.5004\n",
      "Epoch 42/100\n",
      "80000/80000 [==============================] - 3s 43us/step - loss: 0.6826 - binary_crossentropy: 0.6826 - acc: 0.5585 - val_loss: 0.7030 - val_binary_crossentropy: 0.7030 - val_acc: 0.5010\n",
      "Epoch 43/100\n",
      "80000/80000 [==============================] - 3s 42us/step - loss: 0.6824 - binary_crossentropy: 0.6824 - acc: 0.5572 - val_loss: 0.7040 - val_binary_crossentropy: 0.7040 - val_acc: 0.5008\n",
      "Epoch 44/100\n",
      "80000/80000 [==============================] - 4s 49us/step - loss: 0.6820 - binary_crossentropy: 0.6820 - acc: 0.5585 - val_loss: 0.7067 - val_binary_crossentropy: 0.7067 - val_acc: 0.5020\n",
      "Epoch 45/100\n",
      "80000/80000 [==============================] - 4s 46us/step - loss: 0.6818 - binary_crossentropy: 0.6818 - acc: 0.5599 - val_loss: 0.7063 - val_binary_crossentropy: 0.7063 - val_acc: 0.5008\n",
      "Epoch 46/100\n",
      "80000/80000 [==============================] - 3s 38us/step - loss: 0.6816 - binary_crossentropy: 0.6816 - acc: 0.5607 - val_loss: 0.7048 - val_binary_crossentropy: 0.7048 - val_acc: 0.5011\n",
      "Epoch 47/100\n",
      "80000/80000 [==============================] - 3s 40us/step - loss: 0.6813 - binary_crossentropy: 0.6813 - acc: 0.5615 - val_loss: 0.7055 - val_binary_crossentropy: 0.7055 - val_acc: 0.5012\n",
      "Epoch 48/100\n",
      "80000/80000 [==============================] - 4s 53us/step - loss: 0.6810 - binary_crossentropy: 0.6810 - acc: 0.5601 - val_loss: 0.7060 - val_binary_crossentropy: 0.7060 - val_acc: 0.5001\n",
      "Epoch 49/100\n",
      "80000/80000 [==============================] - 3s 40us/step - loss: 0.6807 - binary_crossentropy: 0.6807 - acc: 0.5618 - val_loss: 0.7063 - val_binary_crossentropy: 0.7063 - val_acc: 0.4981\n",
      "Epoch 50/100\n",
      "80000/80000 [==============================] - 3s 39us/step - loss: 0.6807 - binary_crossentropy: 0.6807 - acc: 0.5610 - val_loss: 0.7064 - val_binary_crossentropy: 0.7064 - val_acc: 0.5008\n",
      "Epoch 51/100\n",
      "80000/80000 [==============================] - 3s 37us/step - loss: 0.6804 - binary_crossentropy: 0.6804 - acc: 0.5631 - val_loss: 0.7050 - val_binary_crossentropy: 0.7050 - val_acc: 0.5020\n",
      "Epoch 52/100\n",
      "80000/80000 [==============================] - 3s 33us/step - loss: 0.6801 - binary_crossentropy: 0.6801 - acc: 0.5647 - val_loss: 0.7070 - val_binary_crossentropy: 0.7070 - val_acc: 0.5012\n",
      "Epoch 53/100\n",
      "80000/80000 [==============================] - 4s 45us/step - loss: 0.6800 - binary_crossentropy: 0.6800 - acc: 0.5638 - val_loss: 0.7065 - val_binary_crossentropy: 0.7065 - val_acc: 0.5010\n",
      "Epoch 54/100\n",
      "80000/80000 [==============================] - 3s 43us/step - loss: 0.6800 - binary_crossentropy: 0.6800 - acc: 0.5656 - val_loss: 0.7065 - val_binary_crossentropy: 0.7065 - val_acc: 0.5050\n",
      "Epoch 55/100\n",
      "80000/80000 [==============================] - 4s 45us/step - loss: 0.6795 - binary_crossentropy: 0.6795 - acc: 0.5662 - val_loss: 0.7067 - val_binary_crossentropy: 0.7067 - val_acc: 0.4981\n",
      "Epoch 56/100\n",
      "80000/80000 [==============================] - 4s 48us/step - loss: 0.6794 - binary_crossentropy: 0.6794 - acc: 0.5665 - val_loss: 0.7067 - val_binary_crossentropy: 0.7067 - val_acc: 0.5022\n",
      "Epoch 57/100\n",
      "80000/80000 [==============================] - 4s 46us/step - loss: 0.6791 - binary_crossentropy: 0.6791 - acc: 0.5654 - val_loss: 0.7061 - val_binary_crossentropy: 0.7061 - val_acc: 0.5024\n",
      "Epoch 58/100\n",
      "80000/80000 [==============================] - 3s 44us/step - loss: 0.6791 - binary_crossentropy: 0.6791 - acc: 0.5684 - val_loss: 0.7065 - val_binary_crossentropy: 0.7065 - val_acc: 0.5011\n",
      "Epoch 59/100\n",
      "80000/80000 [==============================] - 4s 49us/step - loss: 0.6789 - binary_crossentropy: 0.6789 - acc: 0.5656 - val_loss: 0.7074 - val_binary_crossentropy: 0.7074 - val_acc: 0.4999\n",
      "Epoch 60/100\n",
      "80000/80000 [==============================] - 4s 48us/step - loss: 0.6785 - binary_crossentropy: 0.6785 - acc: 0.5664 - val_loss: 0.7065 - val_binary_crossentropy: 0.7065 - val_acc: 0.5016\n",
      "Epoch 61/100\n",
      "80000/80000 [==============================] - 3s 37us/step - loss: 0.6787 - binary_crossentropy: 0.6787 - acc: 0.5681 - val_loss: 0.7103 - val_binary_crossentropy: 0.7103 - val_acc: 0.5001\n",
      "Epoch 62/100\n",
      "80000/80000 [==============================] - 3s 41us/step - loss: 0.6784 - binary_crossentropy: 0.6784 - acc: 0.5700 - val_loss: 0.7070 - val_binary_crossentropy: 0.7070 - val_acc: 0.4977\n",
      "Epoch 63/100\n",
      "80000/80000 [==============================] - 4s 50us/step - loss: 0.6782 - binary_crossentropy: 0.6782 - acc: 0.5687 - val_loss: 0.7066 - val_binary_crossentropy: 0.7066 - val_acc: 0.5017\n",
      "Epoch 64/100\n",
      "80000/80000 [==============================] - 4s 47us/step - loss: 0.6779 - binary_crossentropy: 0.6779 - acc: 0.5691 - val_loss: 0.7096 - val_binary_crossentropy: 0.7096 - val_acc: 0.4997\n",
      "Epoch 65/100\n",
      "80000/80000 [==============================] - 3s 35us/step - loss: 0.6779 - binary_crossentropy: 0.6779 - acc: 0.5708 - val_loss: 0.7078 - val_binary_crossentropy: 0.7078 - val_acc: 0.5019\n",
      "Epoch 66/100\n",
      "80000/80000 [==============================] - 3s 34us/step - loss: 0.6778 - binary_crossentropy: 0.6778 - acc: 0.5704 - val_loss: 0.7082 - val_binary_crossentropy: 0.7082 - val_acc: 0.4990\n",
      "Epoch 67/100\n",
      "80000/80000 [==============================] - 3s 38us/step - loss: 0.6775 - binary_crossentropy: 0.6775 - acc: 0.5713 - val_loss: 0.7076 - val_binary_crossentropy: 0.7076 - val_acc: 0.5009\n",
      "Epoch 68/100\n",
      "80000/80000 [==============================] - 3s 39us/step - loss: 0.6774 - binary_crossentropy: 0.6774 - acc: 0.5709 - val_loss: 0.7081 - val_binary_crossentropy: 0.7081 - val_acc: 0.5000\n",
      "Epoch 69/100\n",
      "80000/80000 [==============================] - 3s 40us/step - loss: 0.6773 - binary_crossentropy: 0.6773 - acc: 0.5699 - val_loss: 0.7097 - val_binary_crossentropy: 0.7097 - val_acc: 0.5013\n",
      "Epoch 70/100\n",
      "80000/80000 [==============================] - 3s 34us/step - loss: 0.6771 - binary_crossentropy: 0.6771 - acc: 0.5706 - val_loss: 0.7083 - val_binary_crossentropy: 0.7083 - val_acc: 0.5042\n",
      "Epoch 71/100\n",
      "80000/80000 [==============================] - 3s 34us/step - loss: 0.6773 - binary_crossentropy: 0.6773 - acc: 0.5702 - val_loss: 0.7086 - val_binary_crossentropy: 0.7086 - val_acc: 0.5028\n",
      "Epoch 72/100\n",
      "80000/80000 [==============================] - 3s 38us/step - loss: 0.6768 - binary_crossentropy: 0.6768 - acc: 0.5700 - val_loss: 0.7089 - val_binary_crossentropy: 0.7089 - val_acc: 0.5010\n",
      "Epoch 73/100\n",
      "80000/80000 [==============================] - 3s 33us/step - loss: 0.6766 - binary_crossentropy: 0.6766 - acc: 0.5719 - val_loss: 0.7098 - val_binary_crossentropy: 0.7098 - val_acc: 0.5001\n",
      "Epoch 74/100\n",
      "80000/80000 [==============================] - 3s 33us/step - loss: 0.6765 - binary_crossentropy: 0.6765 - acc: 0.5709 - val_loss: 0.7112 - val_binary_crossentropy: 0.7112 - val_acc: 0.4998\n",
      "Epoch 75/100\n",
      "80000/80000 [==============================] - 3s 33us/step - loss: 0.6765 - binary_crossentropy: 0.6765 - acc: 0.5709 - val_loss: 0.7115 - val_binary_crossentropy: 0.7115 - val_acc: 0.5022\n",
      "Epoch 76/100\n",
      "80000/80000 [==============================] - 3s 34us/step - loss: 0.6764 - binary_crossentropy: 0.6764 - acc: 0.5733 - val_loss: 0.7110 - val_binary_crossentropy: 0.7110 - val_acc: 0.5032\n",
      "Epoch 77/100\n",
      "80000/80000 [==============================] - 3s 34us/step - loss: 0.6764 - binary_crossentropy: 0.6764 - acc: 0.5728 - val_loss: 0.7084 - val_binary_crossentropy: 0.7084 - val_acc: 0.5035\n",
      "Epoch 78/100\n",
      "80000/80000 [==============================] - 3s 34us/step - loss: 0.6762 - binary_crossentropy: 0.6762 - acc: 0.5719 - val_loss: 0.7078 - val_binary_crossentropy: 0.7078 - val_acc: 0.4996\n",
      "Epoch 79/100\n",
      "80000/80000 [==============================] - 3s 33us/step - loss: 0.6757 - binary_crossentropy: 0.6757 - acc: 0.5762 - val_loss: 0.7101 - val_binary_crossentropy: 0.7101 - val_acc: 0.4998\n",
      "Epoch 80/100\n",
      "80000/80000 [==============================] - 3s 34us/step - loss: 0.6758 - binary_crossentropy: 0.6758 - acc: 0.5765 - val_loss: 0.7111 - val_binary_crossentropy: 0.7111 - val_acc: 0.5016\n",
      "Epoch 81/100\n",
      "80000/80000 [==============================] - 3s 37us/step - loss: 0.6758 - binary_crossentropy: 0.6758 - acc: 0.5734 - val_loss: 0.7102 - val_binary_crossentropy: 0.7102 - val_acc: 0.5006\n",
      "Epoch 82/100\n",
      "80000/80000 [==============================] - 3s 36us/step - loss: 0.6757 - binary_crossentropy: 0.6757 - acc: 0.5745 - val_loss: 0.7097 - val_binary_crossentropy: 0.7097 - val_acc: 0.5010\n",
      "Epoch 83/100\n",
      "80000/80000 [==============================] - 3s 35us/step - loss: 0.6756 - binary_crossentropy: 0.6756 - acc: 0.5753 - val_loss: 0.7104 - val_binary_crossentropy: 0.7104 - val_acc: 0.5007\n",
      "Epoch 84/100\n",
      "80000/80000 [==============================] - 3s 37us/step - loss: 0.6756 - binary_crossentropy: 0.6756 - acc: 0.5754 - val_loss: 0.7115 - val_binary_crossentropy: 0.7115 - val_acc: 0.5008\n",
      "Epoch 85/100\n",
      "80000/80000 [==============================] - 3s 38us/step - loss: 0.6754 - binary_crossentropy: 0.6754 - acc: 0.5752 - val_loss: 0.7116 - val_binary_crossentropy: 0.7116 - val_acc: 0.4979\n",
      "Epoch 86/100\n",
      "80000/80000 [==============================] - 3s 40us/step - loss: 0.6753 - binary_crossentropy: 0.6753 - acc: 0.5756 - val_loss: 0.7117 - val_binary_crossentropy: 0.7117 - val_acc: 0.4993\n",
      "Epoch 87/100\n",
      "80000/80000 [==============================] - 3s 36us/step - loss: 0.6753 - binary_crossentropy: 0.6753 - acc: 0.5750 - val_loss: 0.7096 - val_binary_crossentropy: 0.7096 - val_acc: 0.5033\n",
      "Epoch 88/100\n",
      "80000/80000 [==============================] - 3s 40us/step - loss: 0.6752 - binary_crossentropy: 0.6752 - acc: 0.5750 - val_loss: 0.7105 - val_binary_crossentropy: 0.7105 - val_acc: 0.5070\n",
      "Epoch 89/100\n",
      "80000/80000 [==============================] - 3s 36us/step - loss: 0.6748 - binary_crossentropy: 0.6748 - acc: 0.5765 - val_loss: 0.7096 - val_binary_crossentropy: 0.7096 - val_acc: 0.4998\n",
      "Epoch 90/100\n",
      "80000/80000 [==============================] - 3s 37us/step - loss: 0.6750 - binary_crossentropy: 0.6750 - acc: 0.5758 - val_loss: 0.7111 - val_binary_crossentropy: 0.7111 - val_acc: 0.5011\n",
      "Epoch 91/100\n",
      "80000/80000 [==============================] - 3s 35us/step - loss: 0.6747 - binary_crossentropy: 0.6747 - acc: 0.5750 - val_loss: 0.7105 - val_binary_crossentropy: 0.7105 - val_acc: 0.5025\n",
      "Epoch 92/100\n",
      "80000/80000 [==============================] - 3s 37us/step - loss: 0.6745 - binary_crossentropy: 0.6745 - acc: 0.5779 - val_loss: 0.7132 - val_binary_crossentropy: 0.7132 - val_acc: 0.4986\n",
      "Epoch 93/100\n",
      "80000/80000 [==============================] - 3s 37us/step - loss: 0.6747 - binary_crossentropy: 0.6747 - acc: 0.5779 - val_loss: 0.7109 - val_binary_crossentropy: 0.7109 - val_acc: 0.4991\n",
      "Epoch 94/100\n",
      "80000/80000 [==============================] - 3s 36us/step - loss: 0.6744 - binary_crossentropy: 0.6744 - acc: 0.5760 - val_loss: 0.7138 - val_binary_crossentropy: 0.7138 - val_acc: 0.5007\n",
      "Epoch 95/100\n",
      "80000/80000 [==============================] - 3s 41us/step - loss: 0.6745 - binary_crossentropy: 0.6745 - acc: 0.5776 - val_loss: 0.7110 - val_binary_crossentropy: 0.7110 - val_acc: 0.5034\n",
      "Epoch 96/100\n",
      "80000/80000 [==============================] - 3s 33us/step - loss: 0.6743 - binary_crossentropy: 0.6743 - acc: 0.5768 - val_loss: 0.7131 - val_binary_crossentropy: 0.7131 - val_acc: 0.5017\n",
      "Epoch 97/100\n",
      "80000/80000 [==============================] - 3s 37us/step - loss: 0.6743 - binary_crossentropy: 0.6743 - acc: 0.5766 - val_loss: 0.7126 - val_binary_crossentropy: 0.7126 - val_acc: 0.5007\n",
      "Epoch 98/100\n",
      "80000/80000 [==============================] - 3s 36us/step - loss: 0.6742 - binary_crossentropy: 0.6742 - acc: 0.5782 - val_loss: 0.7121 - val_binary_crossentropy: 0.7121 - val_acc: 0.5010\n",
      "Epoch 99/100\n",
      "80000/80000 [==============================] - 3s 35us/step - loss: 0.6742 - binary_crossentropy: 0.6742 - acc: 0.5777 - val_loss: 0.7162 - val_binary_crossentropy: 0.7162 - val_acc: 0.4997\n",
      "Epoch 100/100\n",
      "80000/80000 [==============================] - 3s 36us/step - loss: 0.6739 - binary_crossentropy: 0.6739 - acc: 0.5766 - val_loss: 0.7122 - val_binary_crossentropy: 0.7122 - val_acc: 0.4978\n",
      "20000/20000 [==============================] - 0s 13us/step\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nnHPOxSUPUM455+KSByjnnHNx6f8B/yl2e+A6D4cAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x20c6bb605f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Avg: [ 0.49785]\n",
      "Train Avg: [ 0.5766125]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Overall for: 1_100\n",
      "[ 0.49785]\n",
      "[ 0.5766125]\n",
      "\n",
      "OVERALL VAL: 0.497849996984\n",
      "OVERALL TRAIN: 0.576612498611\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_size = 0.2\n",
    "epochs = [100]\n",
    "b_size = 100\n",
    "tries = 1\n",
    "exp = 'dense_30'\n",
    "\n",
    "\n",
    "histories = np.array([])\n",
    "\n",
    "X, Y = import_data()\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = test_size)\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "Y_train = np.array(Y_train)\n",
    "Y_test = np.array(Y_test)\n",
    "\n",
    "print(\"\\nTraining examples: \" +  str(X_train.shape[0]))\n",
    "print(\"Test examples: \" +  str(X_test.shape[0]))\n",
    "\n",
    "input_size = len(X_train[0][0])\n",
    "\n",
    "\n",
    "neurons = [int(input_size)]\n",
    "\n",
    "for n in neurons:\n",
    "    for ep in epochs:\n",
    "        avg_val = np.array([])\n",
    "        avg_train = np.array([])\n",
    "        for t in range(tries):\n",
    "            print(\"Epochs: \" + str(ep) + '  -------  Try: ' + str(t))\n",
    "            classifier = create_RNN_model(X_train.shape, n)\n",
    "            #classifier.summary()\n",
    "\n",
    "            history = classifier.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs=ep, batch_size=b_size, verbose=1)\n",
    "            result = classifier.evaluate(X_test, Y_test, batch_size=b_size)\n",
    "\n",
    "            avg_val = np.append(avg_val, result[2])\n",
    "            avg_train = np.append(avg_train, history.history['acc'][-1])\n",
    "            histories = np.append(histories, history)\n",
    "\n",
    "            val_acc = history.history['val_acc']\n",
    "            train_acc = history.history['acc']\n",
    "\n",
    "            with open(exp + '/acc_' + str(len(X_train[0])) + '_' + str(ep) + '_' + str(t) + '_' + str(n) + '.txt', \"w\") as file:\n",
    "                file.write('val_acc  ' + str(val_acc))\n",
    "                file.write('\\ntrain_acc  ' + str(train_acc))\n",
    "\n",
    "            fig, ax = draw_figure([train_acc], 'Training Accuracy')\n",
    "            fig, ax = draw_figure([val_acc], 'Validation Accuracy', fig, ax)\n",
    "\n",
    "            ax.grid('on')\n",
    "            fig.tight_layout() \n",
    "            fig.savefig(exp + '/graph_' + str(len(X_train[0])) + '_' + str(ep) + '_' + str(t) + '_' + str(n) + '.pdf')\n",
    "            plt.show() \n",
    "\n",
    "\n",
    "\n",
    "#             print(confusion_matrix(classifier.predict(X_test)>0.5, Y_test))\n",
    "\n",
    "            print(\"\\nValidation Avg: \" + str(avg_val))\n",
    "            print(\"Train Avg: \" + str(avg_train))\n",
    "            print(\"\\n\")\n",
    "\n",
    "#             c = 0\n",
    "#             classifications = (classifier.predict(X_test) > 0.5 ) == Y_test\n",
    "#             for i, flag in enumerate(classifications):\n",
    "#                 if(flag == False and c<=10):\n",
    "#                     print(str(X_test[i]) + \"    \" + str(Y_test[i]))\n",
    "#                     c += 1\n",
    "\n",
    "#             c = 0\n",
    "            with open(exp + '/data_' + str(len(X_train[0])) + '_' + str(ep) + '_' + str(t) + '_' + str(n) + '.txt', \"w\") as file:\n",
    "#                 file.write(str(confusion_matrix(classifier.predict(X_test)>0.5, Y_test)))\n",
    "\n",
    "                file.write(\"\\nValidation Avg: \" + str(np.average(avg_val)))\n",
    "                file.write(\"\\nTrain Avg: \" + str(np.average(avg_train)))\n",
    "                file.write(\"\\n\\n\")\n",
    "\n",
    "#                 for i, flag in enumerate(classifications):\n",
    "#                     if(flag == False and c<=10):\n",
    "#                         file.write('\\n' + str(X_test[i]) + \"    \" + str(Y_test[i]))\n",
    "#                         c += 1\n",
    "\n",
    "\n",
    "            print(\"\\n\\n\")\n",
    "        print(\"\\n Overall for: \" + str(len(X_train[0])) + '_' + str(ep))\n",
    "        print(avg_val)\n",
    "        print(avg_train)\n",
    "        print(\"\\nOVERALL VAL: \" + str(np.average(avg_val)))\n",
    "        print(\"OVERALL TRAIN: \" + str(np.average(avg_train)))\n",
    "        print(\"\\n\")\n",
    "\n",
    "        with open(exp + '/data_' + str(len(X_train[0])) + '_' + str(ep) + '_' + str(n)  + '.txt', \"w\") as file:\n",
    "            file.write(str(avg_val))\n",
    "            file.write(\"\\n\" + str(avg_train))\n",
    "            file.write(\"\\n\\nOVERALL VAL: \" + str(np.average(avg_val)))\n",
    "            file.write(\"\\nOVERALL TRAIN: \" + str(np.average(avg_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(classifier, to_file='model.pdf', show_shapes=True, show_layer_names=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
